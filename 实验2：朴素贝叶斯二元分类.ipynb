{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import sys\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetPath(sc):\n",
    "    global Path\n",
    "    if sc.master[0:5]==\"local\" :\n",
    "        Path=\"file:/home/hduser/pythonwork/PythonProject/\"\n",
    "    else:   \n",
    "        Path=\"hdfs://master:9000/user/hduser/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(record):\n",
    "    label=(record[-1])\n",
    "    return float(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(field,categoriesMap,featureEnd):\n",
    "    categoryIdx = categoriesMap[field[3]]\n",
    "    categoryFeatures = np.zeros(len(categoriesMap))\n",
    "    categoryFeatures[categoryIdx] = 1\n",
    "    numericalFeatures=[convert_float(field)  for  field in field[4: featureEnd]]    \n",
    "    return  np.concatenate(( categoryFeatures, numericalFeatures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float(x):\n",
    "    ret=(0 if x==\"?\" else float(x))\n",
    "    return (0 if ret<0 else ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(sc): \n",
    "    #----------------------1.导入并转换数据-------------\n",
    "    print(\"开始导入数据...\")\n",
    "    rawDataWithHeader = sc.textFile(Path+\"data/train.tsv\")\n",
    "    header = rawDataWithHeader.first() \n",
    "    rawData = rawDataWithHeader.filter(lambda x:x !=header)    \n",
    "    rData=rawData.map(lambda x: x.replace(\"\\\"\", \"\"))    \n",
    "    lines = rData.map(lambda x: x.split(\"\\t\"))\n",
    "    print(\"共计：\" + str(lines.count()) + \"项\")\n",
    "    #----------------------2.建立训练评估所需数据 RDD[LabeledPoint]-------------\n",
    "    print \"标准化之前：\",\n",
    "    categoriesMap = lines.map(lambda fields: fields[3]).distinct().zipWithIndex().collectAsMap()\n",
    "    labelRDD = lines.map(lambda r:  extract_label(r))\n",
    "    featureRDD = lines.map(lambda r:  extract_features(r,categoriesMap,len(r) - 1))\n",
    "    for i in featureRDD.first():\n",
    "        print (str(i)+\",\"),\n",
    "    print \"\"       \n",
    "    print \"标准化之后：\",       \n",
    "    stdScaler = StandardScaler(withMean=False, withStd=True).fit(featureRDD)\n",
    "    ScalerFeatureRDD=stdScaler.transform(featureRDD)\n",
    "    for i in ScalerFeatureRDD.first():\n",
    "        print (str(i)+\",\"),\n",
    "    labelpoint=labelRDD.zip(ScalerFeatureRDD)\n",
    "    labelpointRDD=labelpoint.map(lambda r: LabeledPoint(r[0], r[1]))\n",
    "    #----------------------3.以随机方式将数据分为3个部分并且返回-------------\n",
    "    (trainData, validationData, testData) = labelpointRDD.randomSplit([8, 1, 1])\n",
    "    print(\"将数据分trainData:\" + str(trainData.count()) + \n",
    "              \"   validationData:\" + str(validationData.count()) +\n",
    "              \"   testData:\" + str(testData.count()))\n",
    "    return (trainData, validationData, testData, categoriesMap) #返回数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictData(sc,model,categoriesMap): \n",
    "    print(\"开始导入数据...\")\n",
    "    rawDataWithHeader = sc.textFile(Path+\"data/test.tsv\")\n",
    "    header = rawDataWithHeader.first() \n",
    "    rawData = rawDataWithHeader.filter(lambda x:x !=header)    \n",
    "    rData=rawData.map(lambda x: x.replace(\"\\\"\", \"\"))    \n",
    "    lines = rData.map(lambda x: x.split(\"\\t\"))\n",
    "    print(\"共计：\" + str(lines.count()) + \"项\")\n",
    "    dataRDD = lines.map(lambda r:  ( r[0]  ,\n",
    "                            extract_features(r,categoriesMap,len(r) )))\n",
    "    DescDict = {\n",
    "           0: \"暂时性网页(ephemeral)\",\n",
    "           1: \"长青网页(evergreen)\"\n",
    "     }\n",
    "    for data in dataRDD.take(10):\n",
    "        predictResult = model.predict(data[1])\n",
    "        print \" 网址：  \" +str(data[0])+\"\\n\" +\\\n",
    "                  \"             ==>预测:\"+ str(predictResult)+ \\\n",
    "                  \" 说明:\"+DescDict[predictResult] +\"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, validationData):\n",
    "    score = model.predict(validationData.map(lambda p: p.features))\n",
    "    scoreAndLabels=score.zip(validationData \\\n",
    "                                   .map(lambda p: p.label))  \\\n",
    "                                   .map(lambda (x,y): (float(x),float(y)) )\n",
    "    metrics = BinaryClassificationMetrics(scoreAndLabels)\n",
    "    AUC=metrics.areaUnderROC\n",
    "    return( AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEvaluateModel(trainData,validationData,lambdaParam):\n",
    "    startTime = time()\n",
    "    model = NaiveBayes.train(trainData,lambdaParam)\n",
    "    AUC = evaluateModel(model, validationData)\n",
    "    duration = time() - startTime\n",
    "    print    \"训练评估：使用参数\" + \\\n",
    "                \" lambda=\"+str( lambdaParam) +\\\n",
    "                 \" 所需时间=\"+str(duration) + \\\n",
    "                 \" 结果AUC = \" + str(AUC) \n",
    "    return (AUC,duration,  lambdaParam,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  parametersEval(trainData, validationData):\n",
    "    print(\"----- 评估lambda参数使用 ---------\")\n",
    "    evalParameter(trainData, validationData,\"lambdaParam\", \n",
    "            lambdaParamList=[1.0, 3.0, 5.0, 15.0, 25.0,30.0,35.0,40.0,45.0,50.0,60.0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalParameter(trainData, validationData, evalparm,\n",
    "                  lambdaParamList):\n",
    "    \n",
    "    metrics = [trainEvaluateModel(trainData, validationData, lambdaParam ) \n",
    "                                  for  lambdaParam in  lambdaParamList]\n",
    "    \n",
    "    evalparm=\"lambdaParam\"\n",
    "    IndexList=lambdaParamList\n",
    "    \n",
    "    df = pd.DataFrame(metrics,index=IndexList,\n",
    "            columns=['AUC', 'duration',' lambdaParam','model'])\n",
    "    showchart(df,evalparm,'AUC','duration',0.5,0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showchart(df,evalparm ,barData,lineData,yMin,yMax):\n",
    "    ax = df[barData].plot(kind='bar', title =evalparm,figsize=(10,6),legend=True, fontsize=12)\n",
    "    ax.set_xlabel(evalparm,fontsize=12)\n",
    "    ax.set_ylim([yMin,yMax])\n",
    "    ax.set_ylabel(barData,fontsize=12)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df[[lineData ]].values, linestyle='-', marker='o', linewidth=2.0,color='r')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalAllParameter(training_RDD, validation_RDD, lambdaParamList):    \n",
    "    metrics = [trainEvaluateModel(trainData, validationData,  lambdaParam  ) \n",
    "                        for lambdaParam in lambdaParamList  ]\n",
    "    Smetrics = sorted(metrics, key=lambda k: k[0], reverse=True)\n",
    "    bestParameter=Smetrics[0]\n",
    "    \n",
    "    print(\"调校后最佳参数：lambdaParam:\" + str(bestParameter[2]) +  \n",
    "             \"\\n  ,结果AUC = \" + str(bestParameter[0]))\n",
    "    return bestParameter[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateSparkContext():\n",
    "    sparkConf = SparkConf().setAppName(\"SVMWithSGD\").set(\"spark.ui.showConsoleProgress\", \"false\") \n",
    "    sc = SparkContext(conf = sparkConf)\n",
    "    print (\"master=\"+sc.master)    \n",
    "    SetPath(sc)\n",
    "    return (sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunNaiveBayesBinary\n",
      "master=local[*]\n",
      "==========数据准备阶段===============\n",
      "开始导入数据...\n",
      "共计：7395项\n",
      "标准化之前： 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789131, 2.055555556, 0.676470588, 0.205882353, 0.047058824, 0.023529412, 0.443783175, 0.0, 0.0, 0.09077381, 0.0, 0.245831182, 0.003883495, 1.0, 1.0, 24.0, 0.0, 5424.0, 170.0, 8.0, 0.152941176, 0.079129575, \n",
      "标准化之后： 0.0, 3.088234470373542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.382109905825835, 0.23846925874240185, 3.3301793603170884, 1.4030154477199817, 0.49030735543205883, 0.323968347812901, 0.07779782993228768, 0.0, 0.0, 2.190189633120838, 0.0, 4.683697355817031, 0.002066886525539329, 2.0555083992759973, 2.1113276370640266, 1.17686860239841, 0.0, 0.6111251528371162, 0.9472535877741962, 2.474396677695976, 0.8344415706300091, 0.998721352144073, 将数据分trainData:5929   validationData:706   testData:760\n",
      "==========训练评估阶段===============\n",
      "训练评估：使用参数 lambda=60.0 所需时间=7.49107408524 结果AUC = 0.654031253766\n",
      "-----所有参数训练评估找出最好的参数组合---------\n",
      "训练评估：使用参数 lambda=1.0 所需时间=0.834223031998 结果AUC = 0.647278351344\n",
      "训练评估：使用参数 lambda=3.0 所需时间=0.524420976639 结果AUC = 0.647278351344\n",
      "训练评估：使用参数 lambda=5.0 所需时间=0.470726966858 结果AUC = 0.647278351344\n",
      "训练评估：使用参数 lambda=15.0 所需时间=0.631378173828 结果AUC = 0.648551801711\n",
      "训练评估：使用参数 lambda=25.0 所需时间=0.650302886963 结果AUC = 0.648551801711\n",
      "训练评估：使用参数 lambda=30.0 所需时间=0.579887866974 结果AUC = 0.648551801711\n",
      "训练评估：使用参数 lambda=35.0 所需时间=0.651920080185 结果AUC = 0.651291527739\n",
      "训练评估：使用参数 lambda=40.0 所需时间=0.330390930176 结果AUC = 0.651291527739\n",
      "训练评估：使用参数 lambda=45.0 所需时间=0.772277116776 结果AUC = 0.652661390752\n",
      "训练评估：使用参数 lambda=50.0 所需时间=0.96729683876 结果AUC = 0.652661390752\n",
      "训练评估：使用参数 lambda=60.0 所需时间=0.504245996475 结果AUC = 0.654031253766\n",
      "调校后最佳参数：lambdaParam:60.0\n",
      "  ,结果AUC = 0.654031253766\n",
      "==========测试阶段===============\n",
      "使用test Data测试最佳模型,结果 AUC:0.633539081821\n",
      "==========预测数据===============\n",
      "开始导入数据...\n",
      "共计：3171项\n",
      " 网址：  http://www.lynnskitchenadventures.com/2009/04/homemade-enchilada-sauce.html\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://lolpics.se/18552-stun-grenade-ar\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.xcelerationfitness.com/treadmills.html\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.bloomberg.com/news/2012-02-06/syria-s-assad-deploys-tactics-of-father-to-crush-revolt-threatening-reign.html\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.wired.com/gadgetlab/2011/12/stem-turns-lemons-and-limes-into-juicy-atomizers/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.latimes.com/health/boostershots/la-heb-fat-tax-denmark-20111013,0,2603132.story\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.howlifeworks.com/a/a?AG_ID=1186&cid=7340ci\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://romancingthestoveblog.wordpress.com/2010/01/13/sweet-potato-ravioli-with-lemon-sage-brown-butter-sauce/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://www.funniez.net/Funny-Pictures/turn-men-down.html\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://youfellasleepwatchingadvd.com/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"RunNaiveBayesBinary\")\n",
    "    sc.stop()\n",
    "    sc=CreateSparkContext()\n",
    "    print(\"==========数据准备阶段===============\")\n",
    "    (trainData, validationData, testData, categoriesMap) =PrepareData(sc)\n",
    "    trainData.persist(); validationData.persist(); testData.persist()\n",
    "    print(\"==========训练评估阶段===============\")\n",
    "    \n",
    "    (AUC,duration,  lambdaParam,model)= \\\n",
    "            trainEvaluateModel(trainData, validationData, 60.0)\n",
    "    flag_mark = 2\n",
    "    \n",
    "    if flag_mark == 1:\n",
    "        parametersEval(trainData, validationData)\n",
    "    elif flag_mark !=1:\n",
    "        print(\"-----所有参数训练评估找出最好的参数组合---------\")  \n",
    "        model=evalAllParameter(trainData, validationData, \n",
    "                           [1.0, 3.0, 5.0, 15.0, 25.0,30.0,35.0,40.0,45.0,50.0,60.0])\n",
    " \n",
    "              \n",
    "    print(\"==========测试阶段===============\")\n",
    "    auc = evaluateModel(model, testData)\n",
    "    print(\"使用test Data测试最佳模型,结果 AUC:\" + str(auc))\n",
    "    print(\"==========预测数据===============\")\n",
    "    PredictData(sc, model, categoriesMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
